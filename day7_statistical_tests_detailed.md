# ğŸ§ª Day 7: Statistical Tests - Complete Guide with Mathematical Examples

## ğŸ“Š **Hypothesis Testing Framework**

### **Core Concepts**

#### **Step-by-Step Process:**
1. **State Hypotheses**: Hâ‚€ (null) and Hâ‚ (alternative)
2. **Choose Significance Level**: Î± (typically 0.05)
3. **Select Test Statistic**: Based on data type and assumptions
4. **Calculate Test Statistic**: From sample data
5. **Find p-value**: Probability of observing data given Hâ‚€ is true
6. **Make Decision**: Compare p-value with Î±

#### **Decision Rules:**
- **p-value â‰¤ Î±**: Reject Hâ‚€ (statistically significant)
- **p-value > Î±**: Fail to reject Hâ‚€ (not statistically significant)

#### **Error Types:**
- **Type I Error (Î±)**: Reject true Hâ‚€ (False Positive)
- **Type II Error (Î²)**: Accept false Hâ‚€ (False Negative)
- **Power**: 1 - Î² (probability of correctly rejecting false Hâ‚€)

---

## ğŸ“ˆ **T-Tests**

### **1. One-Sample T-Test**

#### **Purpose:** Test if sample mean differs from known population mean

#### **Formula:**
```
t = (xÌ„ - Î¼â‚€) / (s / âˆšn)

where:
xÌ„ = sample mean
Î¼â‚€ = hypothesized population mean
s = sample standard deviation
n = sample size
df = n - 1
```

#### **Example 1: Coffee Shop Wait Time**

**Problem:** A coffee shop claims average wait time is 5 minutes. You sample 12 customers and get these wait times (in minutes):
`[4.2, 5.1, 6.3, 4.8, 5.5, 4.9, 5.8, 4.6, 5.2, 4.7, 5.4, 5.1]`

Test if actual mean differs from claimed 5 minutes (Î± = 0.05).

**Step 1: State Hypotheses**
- Hâ‚€: Î¼ = 5 (wait time is 5 minutes)
- Hâ‚: Î¼ â‰  5 (wait time is not 5 minutes) [two-tailed test]

**Step 2: Calculate Sample Statistics**
```
n = 12
xÌ„ = (4.2 + 5.1 + 6.3 + 4.8 + 5.5 + 4.9 + 5.8 + 4.6 + 5.2 + 4.7 + 5.4 + 5.1) / 12
xÌ„ = 61.6 / 12 = 5.133

sÂ² = Î£(xáµ¢ - xÌ„)Â² / (n-1)
```

**Calculating each deviation:**
```
(4.2 - 5.133)Â² = (-0.933)Â² = 0.870
(5.1 - 5.133)Â² = (-0.033)Â² = 0.001
(6.3 - 5.133)Â² = (1.167)Â² = 1.361
(4.8 - 5.133)Â² = (-0.333)Â² = 0.111
(5.5 - 5.133)Â² = (0.367)Â² = 0.135
(4.9 - 5.133)Â² = (-0.233)Â² = 0.054
(5.8 - 5.133)Â² = (0.667)Â² = 0.445
(4.6 - 5.133)Â² = (-0.533)Â² = 0.284
(5.2 - 5.133)Â² = (0.067)Â² = 0.004
(4.7 - 5.133)Â² = (-0.433)Â² = 0.187
(5.4 - 5.133)Â² = (0.267)Â² = 0.071
(5.1 - 5.133)Â² = (-0.033)Â² = 0.001

Sum = 3.524
sÂ² = 3.524 / 11 = 0.320
s = âˆš0.320 = 0.566
```

**Step 3: Calculate t-statistic**
```
t = (5.133 - 5.0) / (0.566 / âˆš12)
t = 0.133 / (0.566 / 3.464)
t = 0.133 / 0.163
t = 0.816
```

**Step 4: Find Critical Value and p-value**
```
df = n - 1 = 11
For two-tailed test with Î± = 0.05: tâ‚€.â‚€â‚‚â‚…,â‚â‚ = Â±2.201

|t| = 0.816 < 2.201
p-value â‰ˆ 0.432 > 0.05
```

**Step 5: Conclusion**
Fail to reject Hâ‚€. There's insufficient evidence that the mean wait time differs from 5 minutes.

### **2. Two-Sample T-Test (Independent Samples)**

#### **Purpose:** Compare means of two independent groups

#### **Formula (Equal Variances):**
```
t = (xÌ„â‚ - xÌ„â‚‚) / âˆš[sÂ²â‚š(1/nâ‚ + 1/nâ‚‚)]

where:
sÂ²â‚š = [(nâ‚-1)sâ‚Â² + (nâ‚‚-1)sâ‚‚Â²] / (nâ‚ + nâ‚‚ - 2)  [pooled variance]
df = nâ‚ + nâ‚‚ - 2
```

#### **Example 2: Treatment Effectiveness**

**Problem:** Compare effectiveness of two weight loss programs. 
- Group A (nâ‚ = 8): [3.2, 4.1, 2.8, 3.7, 4.0, 3.5, 3.1, 3.9] kg lost
- Group B (nâ‚‚ = 10): [2.1, 2.8, 1.9, 2.5, 2.3, 2.7, 2.0, 2.4, 2.6, 2.2] kg lost

Test if Group A is more effective (Î± = 0.05).

**Step 1: State Hypotheses**
- Hâ‚€: Î¼â‚ = Î¼â‚‚ (no difference in effectiveness)
- Hâ‚: Î¼â‚ > Î¼â‚‚ (Group A is more effective) [one-tailed test]

**Step 2: Calculate Sample Statistics**

**Group A:**
```
nâ‚ = 8
xÌ„â‚ = (3.2 + 4.1 + 2.8 + 3.7 + 4.0 + 3.5 + 3.1 + 3.9) / 8 = 28.3 / 8 = 3.538

sâ‚Â² = Î£(xâ‚áµ¢ - xÌ„â‚)Â² / (nâ‚-1)
Deviations squared: 0.114, 0.316, 0.544, 0.026, 0.213, 0.001, 0.192, 0.131
Sum = 1.537
sâ‚Â² = 1.537 / 7 = 0.220
```

**Group B:**
```
nâ‚‚ = 10
xÌ„â‚‚ = (2.1 + 2.8 + 1.9 + 2.5 + 2.3 + 2.7 + 2.0 + 2.4 + 2.6 + 2.2) / 10 = 23.5 / 10 = 2.35

sâ‚‚Â² = Î£(xâ‚‚áµ¢ - xÌ„â‚‚)Â² / (nâ‚‚-1)
Deviations squared: 0.063, 0.203, 0.203, 0.023, 0.003, 0.123, 0.123, 0.003, 0.063, 0.023
Sum = 0.830
sâ‚‚Â² = 0.830 / 9 = 0.092
```

**Step 3: Calculate Pooled Variance**
```
sÂ²â‚š = [(8-1)(0.220) + (10-1)(0.092)] / (8 + 10 - 2)
sÂ²â‚š = [7(0.220) + 9(0.092)] / 16
sÂ²â‚š = [1.540 + 0.828] / 16 = 2.368 / 16 = 0.148
```

**Step 4: Calculate t-statistic**
```
t = (3.538 - 2.35) / âˆš[0.148(1/8 + 1/10)]
t = 1.188 / âˆš[0.148(0.125 + 0.10)]
t = 1.188 / âˆš[0.148(0.225)]
t = 1.188 / âˆš0.0333
t = 1.188 / 0.182 = 6.527
```

**Step 5: Find Critical Value**
```
df = 8 + 10 - 2 = 16
For one-tailed test with Î± = 0.05: tâ‚€.â‚€â‚…,â‚â‚† = 1.746

t = 6.527 > 1.746
p-value < 0.001
```

**Step 6: Conclusion**
Reject Hâ‚€. Group A is significantly more effective than Group B.

### **3. Paired T-Test**

#### **Purpose:** Compare two related measurements (before/after, matched pairs)

#### **Formula:**
```
t = dÌ„ / (sâ‚ / âˆšn)

where:
dÌ„ = mean of differences
sâ‚ = standard deviation of differences
df = n - 1
```

#### **Example 3: Before/After Training**

**Problem:** Test if training improves performance scores:

| Subject | Before | After | Difference (d) |
|---------|--------|-------|----------------|
| 1       | 72     | 78    | 6              |
| 2       | 68     | 73    | 5              |
| 3       | 75     | 80    | 5              |
| 4       | 70     | 75    | 5              |
| 5       | 73     | 79    | 6              |
| 6       | 69     | 71    | 2              |
| 7       | 71     | 77    | 6              |
| 8       | 74     | 78    | 4              |

**Step 1: State Hypotheses**
- Hâ‚€: Î¼â‚ = 0 (no improvement)
- Hâ‚: Î¼â‚ > 0 (training improves scores) [one-tailed test]

**Step 2: Calculate Difference Statistics**
```
Differences: [6, 5, 5, 5, 6, 2, 6, 4]
n = 8
dÌ„ = (6 + 5 + 5 + 5 + 6 + 2 + 6 + 4) / 8 = 39 / 8 = 4.875

sâ‚Â² = Î£(dáµ¢ - dÌ„)Â² / (n-1)
Deviations from dÌ„ = 4.875: [1.125, 0.125, 0.125, 0.125, 1.125, -2.875, 1.125, -0.875]
Squared deviations: [1.266, 0.016, 0.016, 0.016, 1.266, 8.266, 1.266, 0.766]
Sum = 12.878
sâ‚Â² = 12.878 / 7 = 1.840
sâ‚ = âˆš1.840 = 1.356
```

**Step 3: Calculate t-statistic**
```
t = 4.875 / (1.356 / âˆš8)
t = 4.875 / (1.356 / 2.828)
t = 4.875 / 0.479
t = 10.177
```

**Step 4: Find Critical Value**
```
df = 8 - 1 = 7
For one-tailed test with Î± = 0.05: tâ‚€.â‚€â‚…,â‚‡ = 1.895

t = 10.177 > 1.895
p-value < 0.001
```

**Step 5: Conclusion**
Reject Hâ‚€. Training significantly improves performance scores.

---

## ğŸ“Š **Z-Tests**

### **One-Sample Z-Test**

#### **Purpose:** Test sample mean when population Ïƒ is known or n > 30

#### **Formula:**
```
z = (xÌ„ - Î¼â‚€) / (Ïƒ / âˆšn)

where Ïƒ is known population standard deviation
```

#### **Example 4: Quality Control**

**Problem:** A factory produces bolts with known Ïƒ = 0.05 mm. Target diameter is 10.0 mm. A sample of 36 bolts has xÌ„ = 10.02 mm. Is the process off-target?

**Step 1: State Hypotheses**
- Hâ‚€: Î¼ = 10.0 (process is on target)
- Hâ‚: Î¼ â‰  10.0 (process is off target) [two-tailed test]

**Step 2: Calculate z-statistic**
```
z = (10.02 - 10.0) / (0.05 / âˆš36)
z = 0.02 / (0.05 / 6)
z = 0.02 / 0.00833
z = 2.40
```

**Step 3: Find Critical Value**
```
For two-tailed test with Î± = 0.05: zâ‚€.â‚€â‚‚â‚… = Â±1.96

|z| = 2.40 > 1.96
p-value = 2 Ã— P(Z > 2.40) = 2 Ã— 0.0082 = 0.0164
```

**Step 4: Conclusion**
Reject Hâ‚€. The process is significantly off-target.

---

## ğŸ” **Chi-Square Tests**

### **1. Chi-Square Goodness of Fit Test**

#### **Purpose:** Test if sample follows expected distribution

#### **Formula:**
```
Ï‡Â² = Î£ (Oáµ¢ - Eáµ¢)Â² / Eáµ¢

where:
Oáµ¢ = observed frequency
Eáµ¢ = expected frequency
df = k - 1 - number of estimated parameters
```

#### **Example 5: Die Fairness**

**Problem:** Test if a die is fair. 600 rolls resulted in:

| Face | 1  | 2  | 3  | 4  | 5  | 6  |
|------|----|----|----|----|----|----|
| Observed | 95 | 103| 98 | 107| 92 | 105|

**Step 1: State Hypotheses**
- Hâ‚€: Die is fair (equal probabilities)
- Hâ‚: Die is not fair

**Step 2: Calculate Expected Frequencies**
```
For fair die: Expected frequency for each face = 600/6 = 100
```

**Step 3: Calculate Chi-Square Statistic**
```
Ï‡Â² = (95-100)Â²/100 + (103-100)Â²/100 + (98-100)Â²/100 + (107-100)Â²/100 + (92-100)Â²/100 + (105-100)Â²/100

Ï‡Â² = 25/100 + 9/100 + 4/100 + 49/100 + 64/100 + 25/100
Ï‡Â² = 0.25 + 0.09 + 0.04 + 0.49 + 0.64 + 0.25 = 1.76
```

**Step 4: Find Critical Value**
```
df = 6 - 1 = 5
For Î± = 0.05: Ï‡Â²â‚€.â‚€â‚…,â‚… = 11.07

Ï‡Â² = 1.76 < 11.07
p-value > 0.05
```

**Step 5: Conclusion**
Fail to reject Hâ‚€. The die appears to be fair.

### **2. Chi-Square Test of Independence**

#### **Purpose:** Test if two categorical variables are independent

#### **Formula:**
```
Ï‡Â² = Î£ Î£ (Oáµ¢â±¼ - Eáµ¢â±¼)Â² / Eáµ¢â±¼

where:
Eáµ¢â±¼ = (Row total Ã— Column total) / Grand total
df = (rows - 1) Ã— (columns - 1)
```

#### **Example 6: Education and Job Satisfaction**

**Problem:** Test if education level and job satisfaction are independent:

|           | Low Satisfaction | High Satisfaction | Total |
|-----------|------------------|-------------------|-------|
| High School | 20              | 30                | 50    |
| College     | 15              | 45                | 60    |
| Graduate    | 10              | 30                | 40    |
| **Total**   | **45**          | **105**           | **150**|

**Step 1: State Hypotheses**
- Hâ‚€: Education and job satisfaction are independent
- Hâ‚: Education and job satisfaction are not independent

**Step 2: Calculate Expected Frequencies**
```
Eâ‚â‚ = (50 Ã— 45) / 150 = 15.0
Eâ‚â‚‚ = (50 Ã— 105) / 150 = 35.0
Eâ‚‚â‚ = (60 Ã— 45) / 150 = 18.0
Eâ‚‚â‚‚ = (60 Ã— 105) / 150 = 42.0
Eâ‚ƒâ‚ = (40 Ã— 45) / 150 = 12.0
Eâ‚ƒâ‚‚ = (40 Ã— 105) / 150 = 28.0
```

**Step 3: Calculate Chi-Square Statistic**
```
Ï‡Â² = (20-15)Â²/15 + (30-35)Â²/35 + (15-18)Â²/18 + (45-42)Â²/42 + (10-12)Â²/12 + (30-28)Â²/28

Ï‡Â² = 25/15 + 25/35 + 9/18 + 9/42 + 4/12 + 4/28
Ï‡Â² = 1.67 + 0.71 + 0.50 + 0.21 + 0.33 + 0.14 = 3.56
```

**Step 4: Find Critical Value**
```
df = (3-1) Ã— (2-1) = 2
For Î± = 0.05: Ï‡Â²â‚€.â‚€â‚…,â‚‚ = 5.99

Ï‡Â² = 3.56 < 5.99
p-value â‰ˆ 0.169 > 0.05
```

**Step 5: Conclusion**
Fail to reject Hâ‚€. Education level and job satisfaction appear to be independent.

---

## ğŸ“ˆ **ANOVA (Analysis of Variance)**

### **One-Way ANOVA**

#### **Purpose:** Compare means of three or more groups

#### **Assumptions:**
1. Normal distribution within groups
2. Equal variances (homoscedasticity)
3. Independent observations

#### **Formula:**
```
F = MSB / MSW = (SSB/(k-1)) / (SSW/(N-k))

where:
SST = Î£(xáµ¢ - xÌ„)Â² (Total Sum of Squares)
SSB = Î£nâ±¼(xÌ„â±¼ - xÌ„)Â² (Between-group Sum of Squares)
SSW = SST - SSB (Within-group Sum of Squares)
```

#### **Example 7: Teaching Methods**

**Problem:** Compare effectiveness of three teaching methods. Test scores:

- **Method A** (nâ‚ = 5): [85, 87, 90, 88, 85]
- **Method B** (nâ‚‚ = 4): [78, 82, 80, 84]
- **Method C** (nâ‚ƒ = 6): [92, 95, 90, 93, 91, 89]

**Step 1: State Hypotheses**
- Hâ‚€: Î¼â‚ = Î¼â‚‚ = Î¼â‚ƒ (all methods equally effective)
- Hâ‚: At least one method differs

**Step 2: Calculate Group Means**
```
Method A: xÌ„â‚ = (85+87+90+88+85)/5 = 435/5 = 87.0
Method B: xÌ„â‚‚ = (78+82+80+84)/4 = 324/4 = 81.0
Method C: xÌ„â‚ƒ = (92+95+90+93+91+89)/6 = 550/6 = 91.67

Overall mean: xÌ„ = (435+324+550)/15 = 1309/15 = 87.27
```

**Step 3: Calculate Sum of Squares**

**SSB (Between-group):**
```
SSB = nâ‚(xÌ„â‚ - xÌ„)Â² + nâ‚‚(xÌ„â‚‚ - xÌ„)Â² + nâ‚ƒ(xÌ„â‚ƒ - xÌ„)Â²
SSB = 5(87.0 - 87.27)Â² + 4(81.0 - 87.27)Â² + 6(91.67 - 87.27)Â²
SSB = 5(0.0729) + 4(39.31) + 6(19.36)
SSB = 0.36 + 157.24 + 116.16 = 273.76
```

**SSW (Within-group):**
```
Method A: (85-87)Â² + (87-87)Â² + (90-87)Â² + (88-87)Â² + (85-87)Â² = 4+0+9+1+4 = 18
Method B: (78-81)Â² + (82-81)Â² + (80-81)Â² + (84-81)Â² = 9+1+1+9 = 20
Method C: (92-91.67)Â² + (95-91.67)Â² + (90-91.67)Â² + (93-91.67)Â² + (91-91.67)Â² + (89-91.67)Â²
         = 0.11 + 11.09 + 2.79 + 1.77 + 0.45 + 7.13 = 23.34

SSW = 18 + 20 + 23.34 = 61.34
```

**Step 4: Calculate Mean Squares and F-statistic**
```
k = 3 (number of groups)
N = 15 (total sample size)

MSB = SSB / (k-1) = 273.76 / 2 = 136.88
MSW = SSW / (N-k) = 61.34 / 12 = 5.11

F = MSB / MSW = 136.88 / 5.11 = 26.78
```

**Step 5: Find Critical Value**
```
dfâ‚ = k - 1 = 2
dfâ‚‚ = N - k = 12
For Î± = 0.05: Fâ‚€.â‚€â‚…,â‚‚,â‚â‚‚ = 3.89

F = 26.78 > 3.89
p-value < 0.001
```

**Step 6: Conclusion**
Reject Hâ‚€. At least one teaching method differs significantly from the others.

**ANOVA Table:**
| Source | SS     | df | MS     | F     | p-value |
|--------|--------|----|--------|-------|---------|
| Between| 273.76 | 2  | 136.88 | 26.78 | <0.001  |
| Within | 61.34  | 12 | 5.11   |       |         |
| Total  | 335.10 | 14 |        |       |         |

---

## ğŸ¯ **Test Selection Guide**

### **Decision Tree for Test Selection:**

```
Is the data continuous?
â”œâ”€â”€ YES
â”‚   â”œâ”€â”€ How many groups?
â”‚   â”‚   â”œâ”€â”€ 1 group
â”‚   â”‚   â”‚   â”œâ”€â”€ Ïƒ known or nâ‰¥30? â†’ Z-test
â”‚   â”‚   â”‚   â””â”€â”€ Ïƒ unknown and n<30? â†’ t-test
â”‚   â”‚   â”œâ”€â”€ 2 groups
â”‚   â”‚   â”‚   â”œâ”€â”€ Independent samples? â†’ Two-sample t-test
â”‚   â”‚   â”‚   â””â”€â”€ Paired samples? â†’ Paired t-test
â”‚   â”‚   â””â”€â”€ 3+ groups â†’ ANOVA
â””â”€â”€ NO (Categorical)
    â”œâ”€â”€ One variable â†’ Chi-square goodness of fit
    â””â”€â”€ Two variables â†’ Chi-square independence
```

### **Key Assumptions Check:**

| Test | Normality | Equal Variance | Independence |
|------|-----------|----------------|--------------|
| t-test | Required | Required (for 2-sample) | Required |
| Z-test | Required | Not critical | Required |
| Chi-square | Not required | Not applicable | Required |
| ANOVA | Required | Required | Required |

### **Effect Size Measures:**

**For t-tests:**
```
Cohen's d = (xÌ„â‚ - xÌ„â‚‚) / spooled

Small effect: d = 0.2
Medium effect: d = 0.5
Large effect: d = 0.8
```

**For ANOVA:**
```
Î·Â² (eta squared) = SSB / SST

Small effect: Î·Â² = 0.01
Medium effect: Î·Â² = 0.06
Large effect: Î·Â² = 0.14
```

**For Chi-square:**
```
CramÃ©r's V = âˆš(Ï‡Â² / (N Ã— min(rows-1, cols-1)))

Small effect: V = 0.1
Medium effect: V = 0.3
Large effect: V = 0.5
```

---

## ğŸ’¡ **Common Mistakes to Avoid**

1. **Multiple Comparisons**: When doing multiple tests, adjust Î± (Bonferroni correction: Î±/number of tests)

2. **Assumption Violations**: Always check normality (Shapiro-Wilk test) and equal variances (Levene's test)

3. **Sample Size**: Ensure adequate power (typically 80%) for meaningful results

4. **One-tailed vs Two-tailed**: Be clear about directionality of hypothesis

5. **Statistical vs Practical Significance**: Large samples can show statistical significance for trivial differences

## ğŸ”‘ **Key Formulas Summary**

| Test | Formula | df |
|------|---------|-----|
| One-sample t | t = (xÌ„ - Î¼â‚€)/(s/âˆšn) | n-1 |
| Two-sample t | t = (xÌ„â‚ - xÌ„â‚‚)/âˆš[sÂ²â‚š(1/nâ‚ + 1/nâ‚‚)] | nâ‚+nâ‚‚-2 |
| Paired t | t = dÌ„/(sâ‚/âˆšn) | n-1 |
| Z-test | z = (xÌ„ - Î¼â‚€)/(Ïƒ/âˆšn) | âˆ |
| Chi-square GoF | Ï‡Â² = Î£(O-E)Â²/E | k-1 |
| Chi-square Independence | Ï‡Â² = Î£Î£(Oáµ¢â±¼-Eáµ¢â±¼)Â²/Eáµ¢â±¼ | (r-1)(c-1) |
| ANOVA | F = MSB/MSW | k-1, N-k |

These comprehensive examples and calculations will help you understand the mathematical foundations of statistical testing for your ML interviews!